{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Data Visualization\n",
    "import plotly\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arctic import Arctic, CHUNK_STORE\n",
    "\n",
    "conn = Arctic('10.213.120.5')\n",
    "lib_entsoe = conn['entsoe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change timezone from UTC to local time\n",
    "\n",
    "def changing_timezone(x):\n",
    "    ts = x.index.tz_localize('utc').tz_convert('Europe/Brussels')\n",
    "    y = x.set_index(ts)\n",
    "    return y.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "perimeter = ['DE','FR', 'BE', 'ES', 'PL', 'IT']\n",
    "      \n",
    "today = date.today()\n",
    "ref_date = today + timedelta(days=-today.weekday(), weeks=-1)\n",
    "start_date = ref_date + timedelta(days=-15)\n",
    "end_date = ref_date + timedelta(days=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(perimeter,start_date,end_date):\n",
    "    \n",
    "    var1 = 'DayAheadPrices'\n",
    "    var2 = 'ActualTotalLoad'\n",
    "    var3 = 'AggregatedGenerationPerType'\n",
    "    var4 = 'DayAheadCommercialSchedules'\n",
    "    \n",
    "    df_1 = lib_entsoe.read(var1 + '_' + perimeter, chunk_range=pd.date_range(start_date, end_date))\n",
    "    df_2 = lib_entsoe.read(var2 + '_' + perimeter, chunk_range=pd.date_range(start_date, end_date))\n",
    "    df_3 = lib_entsoe.read(var3 + '_' + perimeter, chunk_range=pd.date_range(start_date, end_date))\n",
    "    \n",
    "    # convert 15 min data to hourly data\n",
    "    \n",
    "    #df_2 = df_2.resample('H').mean()             \n",
    "    #df_3 = df_3.resample('H').mean()\n",
    "    \n",
    "    # Read cross border flows\n",
    "    \n",
    "    df_exports = pd.DataFrame(columns=[])\n",
    "    df_imports = pd.DataFrame(columns=[])\n",
    "        \n",
    "    if perimeter == 'DE':\n",
    "        interco = ['AT','BE','CZ','DK','FR','LU','NL','PL', 'SE','CH']\n",
    "    elif perimeter == 'FR':\n",
    "        interco = ['BE','DE','IT','ES','CH', 'GB']\n",
    "    elif perimeter == 'BE':\n",
    "        interco = ['FR','DE','LU','NL', 'GB']\n",
    "    elif perimeter == 'ES':\n",
    "        interco = ['FR','PT']\n",
    "    elif perimeter == 'IT':\n",
    "        interco = ['AT','GR','FR','MT','ME','SI','CH']\n",
    "    elif perimeter == 'NL':\n",
    "        interco = ['BE','DK','DE','NO','GB']\n",
    "    elif perimeter == 'PL':\n",
    "        interco = ['CZ','DE','LT','SK','SE']\n",
    "    elif perimeter == 'GB':\n",
    "        interco = ['BE','FR','IE','NL']\n",
    "    \n",
    "    for j in interco:\n",
    "        # exports\n",
    "        prefix = var4 + '_' + perimeter + '_' + j\n",
    "        try:\n",
    "            out_flows = lib_entsoe.read(prefix, chunk_range=pd.date_range(start_date, end_date))\n",
    "            df_exports = pd.merge(df_exports,out_flows ,how='outer',right_index=True, left_index=True)    \n",
    "        except Exception:\n",
    "            pass    \n",
    "        # imports\n",
    "        prefix = var4 + '_' + j + '_' + perimeter\n",
    "        try:\n",
    "            in_flows = lib_entsoe.read(prefix, chunk_range=pd.date_range(start_date, end_date))\n",
    "            df_imports = pd.merge(df_imports,in_flows ,how='outer',right_index=True, left_index=True) \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    flows = df_imports.subtract(df_exports.values).sum(axis =1, skipna= True)\n",
    "    \n",
    "    df_4 = pd.DataFrame(flows, columns = ['Net Imports'])\n",
    "    \n",
    "    # merging data to a single dataframe\n",
    "    \n",
    "    df_merge = pd.DataFrame(columns=[])\n",
    "    \n",
    "    for df in [df_1,df_2,df_3,df_4]:\n",
    "        df_merge = pd.merge(df_merge, df,how='outer',right_index=True, left_index=True)\n",
    "    \n",
    "    # changing timezones \n",
    "    \n",
    "    df_merge = changing_timezone(df_merge)\n",
    "    \n",
    "    # convert 15 min data to hourly data\n",
    "    df_merge = df_merge.resample('H').mean() \n",
    "    \n",
    "    #df_merge.index = pd.to_datetime(df_merge.index)\n",
    "    \n",
    "    df_merge=df_merge.loc[(df_merge.index.date>start_date)&(df_merge.index.date<end_date)]\n",
    "        \n",
    "    for i in ['ActualConsumption','Biomass','Waste','Other renewable', 'Oil', 'Geothermal', 'Other','Marine',\n",
    "             'Coal-derived gas','Peat']:\n",
    "    \n",
    "        df_merge = df_merge[df_merge.columns.drop(list(df_merge.filter(regex=i)))]\n",
    "        \n",
    "    df_merge.columns = df_merge.columns.str.replace(r'DayAheadPrices_'+perimeter, 'Spot price')\n",
    "        \n",
    "    df_merge.columns = df_merge.columns.str.replace(r'ActualGenerationOutput ' + perimeter + ' ', '')\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'ActualTotalLoad_'+ perimeter, 'Demand')\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'Fossil Gas', 'Gas')\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'Fossil Hard coal', 'Coal')\n",
    "\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'Hydro Water Reservoir', 'Hydro Res')\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'Hydro Run-of-river and poundage', 'Hydro R-o-R')\n",
    "    df_merge.columns = df_merge.columns.str.replace(r'Hydro Pumped Storage', 'Hydro Pump')\n",
    "    \n",
    "    try:\n",
    "        df_merge.columns = df_merge.columns.str.replace(r'Fossil Brown coal/Lignite', 'Lignite')\n",
    "        \n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df_merge['Residual load'] = df_merge['Demand'] -(df_merge['Solar'] + df_merge['Wind Onshore'] + df_merge['Wind Offshore'])\n",
    "        df_merge['RES_pen'] = ((df_merge['Solar'] + df_merge['Wind Onshore'] + df_merge['Wind Offshore'])/df_merge['Demand'])*100\n",
    "    except KeyError:\n",
    "        df_merge['Residual load'] = df_merge['Demand'] -(df_merge['Solar'] + df_merge['Wind Onshore'])\n",
    "        df_merge['RES_pen'] = ((df_merge['Solar'] + df_merge['Wind Onshore'])/df_merge['Demand'])*100\n",
    "\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weekly_data(perimeter, start_date, end_date):\n",
    "    dF = pd.DataFrame()\n",
    "    dg = load_data(perimeter, start_date,end_date)\n",
    "    \n",
    "    path = 'data/daily'\n",
    "    filename = perimeter+'_daily.csv'\n",
    "    dg.to_csv(os.path.join(path,filename))\n",
    "    \n",
    "    dg = dg.resample('W').mean()\n",
    "    dg.index = dg.index.week\n",
    "    dg = dg.rename('W/{}'.format)\n",
    "    \n",
    "    path = 'data/weekly'\n",
    "    filename = perimeter+'_weekly.csv'\n",
    "    dg.to_csv(os.path.join(path,filename))\n",
    "    \n",
    "    dF = dF.append(dg)\n",
    "    \n",
    "    #dF.loc[:, dF.columns != 'Spot price' or dF.columns != 'RES_pen' ]/=1000\n",
    "    dF.loc[:,~dF.columns.isin(['Spot price', 'RES_pen'])]/=1000\n",
    "\n",
    "    dF=dF.transpose()\n",
    "    dF=dF.reset_index()\n",
    "    dF['\\u0394 (W-o-W)'] = dF.iloc[:,-1] - dF.iloc[:,-2]\n",
    "    dF = dF.rename({'index': ''},axis =1)\n",
    "\n",
    "    return dF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hourly_data(perimeter, ref_date, end_date):\n",
    "    start_date = ref_date + timedelta(days=-1)\n",
    "    df = load_data(perimeter, start_date,end_date)\n",
    "    \n",
    "    df.loc[:,~df.columns.isin(['Spot price', 'RES_pen'])]/=1000\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3431730"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = plotly.subplots.make_subplots(\n",
    "        rows=3, cols=2, \n",
    "        subplot_titles = perimeter,\n",
    "        shared_xaxes=False,\n",
    "        vertical_spacing=0.1,\n",
    "        specs=[[{\"type\": \"table\"}, {'type' : 'table'}],\n",
    "           [{\"type\": \"table\"}, {'type' : 'table'}],\n",
    "           [{\"type\": \"table\"}, {'type' : 'table'}]]\n",
    ")\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "headerColor = 'light blue'\n",
    "rowEvenColor = 'lightgrey'\n",
    "rowOddColor = 'white'\n",
    "\n",
    "for j in range(len(perimeter)): \n",
    "    if ((j+1) % 2) == 0:\n",
    "        k = 2\n",
    "    else:\n",
    "        k = 1\n",
    "    df = prepare_weekly_data(perimeter[j], start_date, end_date)\n",
    "    data = go.Table(header=dict(values=list(df.columns),\n",
    "                fill_color=headerColor,\n",
    "                align=['left','center'],\n",
    "                ),\n",
    "                cells=dict(values=df.transpose(),\n",
    "                fill_color = [[rowOddColor,rowEvenColor]*9],\n",
    "                align=['left','center'],\n",
    "                format = ['','.1f']\n",
    "              )) \n",
    "    fig.add_trace(data, -(-(j+1)//2), k)\n",
    "\n",
    "# Add figure title\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Weekly Power Report (\" + ref_date.strftime('%d-%b/%Y') + \" - \" + (end_date-timedelta(days=1)).strftime('%d-%b/%Y') + \")\",\n",
    "    height=1100,\n",
    "    #annotations=[\n",
    "    #    go.layout.Annotation(\n",
    "    #        showarrow=False,\n",
    "    #        text='Source: ENTSOE',\n",
    "    #        xanchor='right',\n",
    "    #        x=1,\n",
    "    #        yanchor='top',\n",
    "    #        y=0.01,\n",
    "    #        font=dict(color='grey', size=9)\n",
    "    #    )]\n",
    ")\n",
    "\n",
    "outdir = 'plots/'\n",
    "\n",
    "outfile = 'Weekly Power Report - W'+ (end_date-timedelta(days=1)).strftime('%V-%Y') + '.html'\n",
    "\n",
    "filename = os.path.join(outdir, outfile)\n",
    "\n",
    "f = open(filename,\"w\")  # append mode \n",
    "f.write(fig.to_html(full_html=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = { \n",
    "    'Nuclear' : 'indianred',\n",
    "    'Coal': 'brown',\n",
    "    'Lignite' : 'saddlebrown',\n",
    "    'Gas' : 'silver',\n",
    "    'Hydro R-o-R' : 'blue',\n",
    "    'Hydro Pumped' : 'orange',\n",
    "    'Hydro Res' : 'plum',\n",
    "    'Solar' : 'gold',\n",
    "    'Wind Offshore' : 'green',\n",
    "    'Wind Onshore': 'steelblue'\n",
    "    }\n",
    "\n",
    "countries_dict = {\n",
    "  \"DE\": \"indianred\",\n",
    "  \"FR\": \"royalblue\",\n",
    "  \"BE\": \"rosybrown\",\n",
    "  \"ES\": \"tomato\",\n",
    "  \"IT\": \"green\",\n",
    "  \"NL\": \"orange\",\n",
    "  \"PL\": \"silver\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plotly.subplots.make_subplots(\n",
    "    rows=7, cols=1, row_heights=[0.22, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13],\n",
    "    subplot_titles = (['Spot Price'] + perimeter),\n",
    "    shared_xaxes=False,\n",
    "    vertical_spacing=0.05\n",
    ")\n",
    "\n",
    "\n",
    "for j in range(len(perimeter)):\n",
    "    \n",
    "    df = prepare_hourly_data(perimeter[j], ref_date, end_date)\n",
    "    # Spot prices\n",
    "    var = 'Spot price'  \n",
    "    trace = go.Scatter(x = df.index, \n",
    "                       y = df[var], \n",
    "                       name = perimeter[j],\n",
    "                       line_color = countries_dict[perimeter[j]])\n",
    "    fig.append_trace(trace, 1, 1)\n",
    "\n",
    "for j in range(len(perimeter)):\n",
    "    \n",
    "    df = prepare_hourly_data(perimeter[j], ref_date, end_date)\n",
    "    # Generation\n",
    "  \n",
    "    for i in gen_dict.keys():\n",
    "        try:\n",
    "            trace = go.Bar(x = df.index, \n",
    "                       y = df[i], \n",
    "                       name = i,\n",
    "                       marker_color = gen_dict[i],\n",
    "                       hovertemplate='%{x},%{y:.1f}',\n",
    "                       legendgroup = i,\n",
    "                       showlegend= False if j>0 else True\n",
    "                          )\n",
    "            fig.append_trace(trace, j+2, 1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "  \n",
    "    # CrossBorder Trade\n",
    "  \n",
    "    var = 'Net Imports'\n",
    "    trace = go.Bar(x = df.index, \n",
    "                   y = df[var], \n",
    "                   name = 'Imports/Exports',\n",
    "                   marker_color = 'orchid',\n",
    "                   hovertemplate='%{x},%{y:.1f}',\n",
    "                   legendgroup = 'g1',\n",
    "                   showlegend= False if j>0 else True,\n",
    ")\n",
    "\n",
    "    fig.add_trace(trace, j+2, 1)\n",
    "  \n",
    "    # Demand\n",
    "  \n",
    "    var = 'Demand'\n",
    "    trace = go.Scatter(x = df.index, \n",
    "                       y = df[var], \n",
    "                       name = 'Demand',\n",
    "                       visible = 'legendonly',\n",
    "                       line = dict(color='black', width=3),\n",
    "                       hovertemplate='%{x},%{y:.1f}',\n",
    "                       legendgroup = 'g2',\n",
    "                       showlegend= False if j>0 else True)\n",
    "    \n",
    "    fig.add_trace(trace, j+2, 1)    \n",
    "    \n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Hourly Stack\",\n",
    "    barmode='relative',\n",
    "    bargap=0,\n",
    "    height=1600,\n",
    "    \n",
    "    xaxis=dict(\n",
    "    autorange=True),\n",
    "  \n",
    "    yaxis1= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "\n",
    "    yaxis2= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "    \n",
    "     yaxis3= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "\n",
    "    yaxis4= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "    \n",
    "    yaxis5= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "\n",
    "    yaxis6= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"),\n",
    "    \n",
    "     yaxis7= dict(\n",
    "       anchor = \"x\",\n",
    "       autorange = True,\n",
    "       title_text = \"€/MWh\"))\n",
    "                       \n",
    "f.write(fig.to_html(full_html=False))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demand_evl\n",
    "\n",
    "f = open(filename,\"a\")  # append mode \n",
    "f.write(demand_evl.fig.to_html(full_html=False))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate email\n",
    "# correct demand evolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n",
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfkit\n",
    "path_wkhtmltopdf = r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe'\n",
    "config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
    "pdfkit.from_url(\"http://google.com\", \"out.pdf\", configuration=config)\n",
    "pdfkit.from_file(os.path.join(outdir, outfile), outfile_pdf, configuration=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xhtml2pdf import pisa             # import python module\n",
    "\n",
    "# Utility function\n",
    "def convert_html_to_pdf(source_html, output_filename):\n",
    "    # open output file for writing (truncated binary)\n",
    "    result_file = open(output_filename, \"w+b\")\n",
    "\n",
    "    # convert HTML to PDF\n",
    "    pisa_status = pisa.CreatePDF(\n",
    "            source_html,                # the HTML to convert\n",
    "            dest=result_file)           # file handle to recieve result\n",
    "\n",
    "    # close output file\n",
    "    result_file.close()                 # close output file\n",
    "\n",
    "    # return True on success and False on errors\n",
    "    return pisa_status.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMPT server connection error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import os.path\n",
    "\n",
    "\n",
    "def send_email(email_recipient,\n",
    "               email_subject,\n",
    "               email_message,\n",
    "               attachment_location = ''):\n",
    "\n",
    "    email_sender = 'ashank.sinha@arcelormittal.com'\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = email_sender\n",
    "    msg['To'] = email_recipient\n",
    "    msg['Subject'] = email_subject\n",
    "\n",
    "    msg.attach(MIMEText(email_message, 'plain'))\n",
    "\n",
    "    if attachment_location != '':\n",
    "        filename = os.path.basename(attachment_location)\n",
    "        attachment = open(attachment_location, \"rb\")\n",
    "        part = MIMEBase('application', 'octet-stream')\n",
    "        part.set_payload(attachment.read())\n",
    "        encoders.encode_base64(part)\n",
    "        part.add_header('Content-Disposition',\n",
    "                        \"attachment; filename= %s\" % filename)\n",
    "        msg.attach(part)\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp.office365.com', 587)\n",
    "        server.ehlo()\n",
    "        server.starttls()\n",
    "        server.login('A0743104@arcelormittal.lu', 'AMElux@3')\n",
    "        text = msg.as_string()\n",
    "        server.sendmail(email_sender, email_recipient, text)\n",
    "        print('email sent')\n",
    "        server.quit()\n",
    "    except:\n",
    "        print(\"SMPT server connection error\")\n",
    "    return True\n",
    "\n",
    "send_email('tom.bausch@arcelormittal.com',\n",
    "           'Weekly Power Report',\n",
    "           'Hello', \n",
    "           os.path.join('plots/', 'Weekly Power Report.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
